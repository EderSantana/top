{
 "metadata": {
  "name": "",
  "signature": "sha256:2993dd402682b36b2d7c1cdaaed819a13084e69e7b3addae502c8a2485b0b150"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Iteractive learning rate and plotting\n",
      "=====\n",
      "\n",
      "NOTE: If you want to use Bokeh plots for a beautiful experience, first start install bokeh\n",
      "\n",
      "    $ pip install bokeh\n",
      "    \n",
      "and start a bokeh server\n",
      "\n",
      "    $ bokeh-server\n",
      "\n",
      "After you change the learning rate once, the plot will only show at [localhost:5006](http://localhost:5006).\n",
      "You can also start the bokeh server to listen to a different ip with\n",
      "\n",
      "    $ bokeh-server --ip your.i.p.here\n",
      "\n",
      "Than, make sure to input `bokeh_server=http://your.i.p.here:5006` to `top.Optimizer`.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import top\n",
      "import theano\n",
      "import theano.tensor as tensor\n",
      "from top.dataset_iterator import (Pylearn2DatasetGenerator,\n",
      "                                  Pylearn2OldGenerator,\n",
      "                                  NumpyDatasetGenerator)\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from IPython import display"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Random dataset\n",
      "dataset = np.random.normal(0,1,(10000,10))\n",
      "# target = 0 if sum>.5 else 1\n",
      "target  = 0. + (np.dot(dataset, np.ones((10,1)))>.5)\n",
      "dataset_generator = NumpyDatasetGenerator(\n",
      "                          dataset=(dataset, target),\n",
      "                          batch_size=100\n",
      "                          )\n",
      "W  = theano.shared(np.random.normal(0,1,(10,1)).astype(top.up.floatX))\n",
      "X, T = tensor.matrices('X', 'Y')\n",
      "Y = tensor.nnet.sigmoid(tensor.dot(X,W))\n",
      "cost = tensor.nnet.binary_crossentropy(Y, T).mean()\n",
      "opt = top.Optimizer(W, cost, input=[X,T], method='sgd', learning_rate=.005, ipython_display=display, \n",
      "                    bokeh_server='localhost:5006')\n",
      "#print W.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the next cell, we define which variables we want to iteract with. \n",
      "We create a theano function to update those variables and\n",
      "pass that function as an `IPythonhtml.widgets.iteract update`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.html.widgets import interact\n",
      "import threading\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "\n",
      "newlr = T.scalar()\n",
      "uplr = theano.function([newlr],[],updates={opt.lr: newlr})\n",
      "def update(learning_rate=0.00001):\n",
      "    uplr(learning_rate)\n",
      "    try:\n",
      "        opt.bplt.show(opt.fig)\n",
      "    except:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we launch the main loop as a `Thread`. This will allow `IPythonhtml.widgets.iteract` work in parallel to the training algorithm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class OPT(threading.Thread):\n",
      "    '''Wrap the main loop as a thread'''\n",
      "    def run(self):\n",
      "        opt.iterate_epochs(1000, dataset_generator)\n",
      "        print 'Finish!!!'\n",
      "        print W.get_value()\n",
      "\n",
      "_ = interact(update, learning_rate=(0.00001,.01,0.00005))    \n",
      "OPT().start()\n",
      "#opt.iterate_epochs(1000, dataset_generator)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}